{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0179637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.madlib import MadlibModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f548e17b",
   "metadata": {},
   "source": [
    "## Setting up the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! PyTorch can use the GPU.\")\n",
    "    # You can also get more info about the GPU\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU device name: {torch.cuda.get_device_name(0)}\") # 0 is the index of the first GPU\n",
    "else:\n",
    "    print(\"CUDA is NOT available. PyTorch will run on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01404a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90583c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MadlibModel(num_labels=2, epsilon=epsilon)\n",
    "tokenizer = model.tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0613a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = model.original_emb.weight  # Shape: (vocab_size, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71494f",
   "metadata": {},
   "source": [
    "## Setting up the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ebc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset  import MovieDataset  # Certifique-se de que o arquivo dataset.py está no mesmo diretório\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = MovieDataset(train=True, max_length=128)\n",
    "test_dataset = MovieDataset(train=False, max_length=128)\n",
    "\n",
    "num_labels = train_dataset.num_labels # Get num_labels from dataset\n",
    "\n",
    "# Instantiate DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4720ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_word_embeddings_distilbert_batch(input_ids, attention_mask, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Generates token embeddings for a batch of tokenized inputs using DistilBERT.\n",
    "    Maps tokens (excluding padding) to their embeddings for each example in the batch.\n",
    "\n",
    "    Args:\n",
    "        input_ids (torch.Tensor): Tensor of shape (batch_size, seq_len).\n",
    "        attention_mask (torch.Tensor): Tensor of shape (batch_size, seq_len).\n",
    "        tokenizer: The DistilBertTokenizer instance.\n",
    "        model: The DistilBertModel instance.\n",
    "\n",
    "    Returns:\n",
    "        list of tuple (input_id,embeddibg)\n",
    "    \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        token_embeddings_batch = model.get_embeddings(input_ids)  # (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "    return input_ids,token_embeddings_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8acabd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_token_embeddings(data_loader, model, device):\n",
    "    idx = []\n",
    "    embeddings = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y, att_mask in tqdm(data_loader, desc=\"epoch\"):\n",
    "            x, y, att_mask = x.to(device), y.to(device), att_mask.to(device)\n",
    "            token_embeddings_batch = model.get_embeddings(x)  # (batch_size, seq_len, hidden_dim)\n",
    "            mask = att_mask.bool()\n",
    "            for i in range(x.size(0)):\n",
    "                valid_indices = mask[i].nonzero(as_tuple=True)[0]\n",
    "                valid_tokens = x[i][valid_indices].cpu().tolist()\n",
    "                valid_embeds = token_embeddings_batch[i][valid_indices].cpu()\n",
    "                idx.append(valid_tokens)\n",
    "                embeddings.append(valid_embeds)\n",
    "    return idx, embeddings\n",
    "\n",
    "# Example usage:\n",
    "idx_test, embeddings_test = collect_token_embeddings(test_loader, model, device)\n",
    "idx_train, embeddings_train = collect_token_embeddings(train_loader, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd784f",
   "metadata": {},
   "source": [
    "## To each token, find the other token in embedding_matrix that is closer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d60c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425fe08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0c7cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size parameter\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def compute_closest_embeddings(idx_list, embedding_list, embedding_matrix, tokenizer, batch_size=1024):\n",
    "    \"\"\"\n",
    "    Computes the most similar tokens (from a reference embedding matrix) for a list of token embeddings.\n",
    "\n",
    "    Args:\n",
    "        idx_list (list[list[int]]): List of lists, each containing token IDs for a sentence.\n",
    "        embedding_list (list[Tensor]): List of embedding tensors (one per sentence).\n",
    "        embedding_matrix (Tensor): Tensor of shape (V, D) with reference embeddings.\n",
    "        tokenizer: HuggingFace tokenizer.\n",
    "        batch_size (int): Batch size for processing individual tokens.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns:\n",
    "            - sentence_id\n",
    "            - original_token_id\n",
    "            - closest_token_id\n",
    "            - similarity\n",
    "            - original_token\n",
    "            - closest_token\n",
    "    \"\"\"\n",
    "    device = embedding_matrix.device\n",
    "    embedding_matrix_norm = F.normalize(embedding_matrix, p=2, dim=1)  # (V, D)\n",
    "\n",
    "    # Flatten all tokens and embeddings into single lists\n",
    "    all_token_ids = []\n",
    "    all_embeddings = []\n",
    "    all_sentence_ids = []\n",
    "    \n",
    "    for sent_id, (token_ids, embeddings) in enumerate(zip(idx_list, embedding_list)):\n",
    "        all_token_ids.extend(token_ids)\n",
    "        all_embeddings.extend([emb for emb in embeddings])  # Individual token embeddings\n",
    "        all_sentence_ids.extend([sent_id] * len(token_ids))\n",
    "\n",
    "    # Now process in batches of individual tokens\n",
    "    all_original_token_ids = []\n",
    "    all_closest_token_ids = []\n",
    "    all_similarities = []\n",
    "    all_batch_sentence_ids = []\n",
    "\n",
    "    num_tokens = len(all_token_ids)\n",
    "    \n",
    "    for batch_start in tqdm(range(0, num_tokens, batch_size), desc=\"Processing token batches\"):\n",
    "        batch_end = min(batch_start + batch_size, num_tokens)\n",
    "        \n",
    "        batch_token_ids = all_token_ids[batch_start:batch_end]\n",
    "        batch_embeddings = all_embeddings[batch_start:batch_end]\n",
    "        batch_sentence_ids = all_sentence_ids[batch_start:batch_end]\n",
    "\n",
    "        # Stack and normalize - now all embeddings have the same size\n",
    "        stacked_embeddings = torch.stack(batch_embeddings).to(device)  # (batch_size, D)\n",
    "        emb_norm = F.normalize(stacked_embeddings, p=2, dim=1)         # (batch_size, D)\n",
    "\n",
    "        # Cosine similarity: (batch_size, D) × (D, V) → (batch_size, V)\n",
    "        similarities = torch.matmul(emb_norm, embedding_matrix_norm.T)\n",
    "\n",
    "        # Get max similarity and index for each token\n",
    "        closest_similarities, closest_indices = torch.max(similarities, dim=1)\n",
    "\n",
    "        # Store results\n",
    "        all_original_token_ids.extend(batch_token_ids)\n",
    "        all_closest_token_ids.extend(closest_indices.cpu().tolist())\n",
    "        all_similarities.extend(closest_similarities.cpu().tolist())\n",
    "        all_batch_sentence_ids.extend(batch_sentence_ids)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df_results = pd.DataFrame({\n",
    "        \"sentence_id\": all_batch_sentence_ids,\n",
    "        \"original_token_id\": all_original_token_ids,\n",
    "        \"closest_token_id\": all_closest_token_ids,\n",
    "        \"similarity\": all_similarities\n",
    "    })\n",
    "\n",
    "    # Add token strings\n",
    "    df_results[\"original_token\"] = tokenizer.convert_ids_to_tokens(df_results[\"original_token_id\"])\n",
    "    df_results[\"closest_token\"] = tokenizer.convert_ids_to_tokens(df_results[\"closest_token_id\"])\n",
    "\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c4ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = compute_closest_embeddings(\n",
    "    idx_list=idx_train + idx_test,\n",
    "    embedding_list=embeddings_train + embeddings_test,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa52c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a9d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(f\"data/closest_tokens_distilbert_epsilon{epsilon}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "name_generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
