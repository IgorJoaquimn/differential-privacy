{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0179637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.madlib import MadlibModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c01a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f548e17b",
   "metadata": {},
   "source": [
    "## Setting up the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! PyTorch can use the GPU.\")\n",
    "    # You can also get more info about the GPU\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU device name: {torch.cuda.get_device_name(0)}\") # 0 is the index of the first GPU\n",
    "else:\n",
    "    print(\"CUDA is NOT available. PyTorch will run on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01404a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90583c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MadlibModel(num_labels=2, epsilon=epsilon)\n",
    "tokenizer = model.tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0613a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = model.original_emb.weight  # Shape: (vocab_size, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71494f",
   "metadata": {},
   "source": [
    "## Setting up the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4720ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_token_embeddings_in_batches(model, tokenizer, device, batch_size=32, num_repeats=1000):\n",
    "    model.eval()\n",
    "    token_ids = list(tokenizer.get_vocab().values())\n",
    "    idx = []\n",
    "    embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(token_ids), batch_size), desc=\"Collecting token embeddings\"):\n",
    "            batch_token_ids = token_ids[i:i+batch_size]\n",
    "\n",
    "            # Create input tensor: each token ID repeated `num_repeats` times\n",
    "            input_ids = torch.tensor(batch_token_ids, dtype=torch.long, device=device)  # (batch_size,)\n",
    "            input_ids = input_ids.repeat_interleave(num_repeats).view(-1, 1)  # (batch_size * num_repeats, 1)\n",
    "\n",
    "            # Get embeddings: (batch_size * num_repeats, 1, hidden_dim)\n",
    "            token_embeds = model.get_embeddings(input_ids).squeeze(1).cpu()  # (batch_size * num_repeats, hidden_dim)\n",
    "\n",
    "            # Split back per token\n",
    "            for j, token_id in enumerate(batch_token_ids):\n",
    "                start = j * num_repeats\n",
    "                end = start + num_repeats\n",
    "                idx.append(token_id)\n",
    "                embeddings.append(token_embeds[start:end])  # (num_repeats, hidden_dim)\n",
    "\n",
    "    return idx, embeddings\n",
    "\n",
    "idx, embeddings = collect_token_embeddings_in_batches(\n",
    "    model, tokenizer, device,\n",
    "    batch_size=1024,\n",
    "    num_repeats=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8acabd3",
   "metadata": {},
   "source": [
    "## To each token, find the other token in embedding_matrix that is closer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_closest_embeddings(idx_list, embedding_list, embedding_matrix, tokenizer, batch_size=1024):\n",
    "    \"\"\"\n",
    "    Computes the most similar tokens (from a reference embedding matrix) for a list of token embeddings.\n",
    "\n",
    "    Args:\n",
    "        idx_list (list[int]): List of token IDs (flat list).\n",
    "        embedding_list (list[Tensor]): List of token embedding tensors (one per token).\n",
    "        embedding_matrix (Tensor): Tensor of shape (V, D) with reference embeddings.\n",
    "        tokenizer: HuggingFace tokenizer.\n",
    "        batch_size (int): Batch size for processing.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns:\n",
    "            - token_id\n",
    "            - closest_token_id\n",
    "            - similarity\n",
    "            - token\n",
    "            - closest_token\n",
    "    \"\"\"\n",
    "    device = embedding_matrix.device\n",
    "    embedding_matrix_norm = F.normalize(embedding_matrix, p=2, dim=1)  # (V, D)\n",
    "\n",
    "    # Validate input lengths\n",
    "    assert len(idx_list) == len(embedding_list), \"Mismatch between idx_list and embedding_list lengths\"\n",
    "\n",
    "    # Prepare containers\n",
    "    all_closest_token_ids = []\n",
    "    all_similarities = []\n",
    "\n",
    "    num_tokens = len(idx_list)\n",
    "    \n",
    "    for batch_start in tqdm(range(0, num_tokens, batch_size), desc=\"Processing token batches\"):\n",
    "        batch_end = min(batch_start + batch_size, num_tokens)\n",
    "\n",
    "        batch_token_ids = idx_list[batch_start:batch_end]\n",
    "        batch_embeddings = embedding_list[batch_start:batch_end]\n",
    "\n",
    "        # Stack and normalize embeddings\n",
    "        stacked_embeddings = torch.stack(batch_embeddings).to(device)  # (batch_size, D)\n",
    "        emb_norm = F.normalize(stacked_embeddings, p=2, dim=1)         # (batch_size, D)\n",
    "\n",
    "        # Compute cosine similarity: (batch_size, D) × (D, V)ᵗ = (batch_size, V)\n",
    "        similarities = torch.matmul(emb_norm, embedding_matrix_norm.T)\n",
    "\n",
    "        # Find the most similar token in the vocab\n",
    "        closest_similarities, closest_indices = torch.max(similarities, dim=1)\n",
    "\n",
    "        # Store results\n",
    "        all_closest_token_ids.extend(closest_indices.cpu().tolist())\n",
    "        all_similarities.extend(closest_similarities.cpu().tolist())\n",
    "\n",
    "    # Create DataFrame\n",
    "    df_results = pd.DataFrame({\n",
    "        \"token_id\": idx_list,\n",
    "        \"closest_token_id\": all_closest_token_ids,\n",
    "        \"similarity\": all_similarities\n",
    "    })\n",
    "\n",
    "    # Add string representations\n",
    "    df_results[\"token\"] = tokenizer.convert_ids_to_tokens(df_results[\"token_id\"])\n",
    "    df_results[\"closest_token\"] = tokenizer.convert_ids_to_tokens(df_results[\"closest_token_id\"])\n",
    "\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c4ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = compute_closest_embeddings(\n",
    "    idx_list=idx,\n",
    "    embedding_list=embeddings,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa52c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[\"original_token_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81812c1",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "k = 10  # You can change k as needed\n",
    "\n",
    "# Top k most common original_token\n",
    "most_common = df_results[\"original_token\"].value_counts().head(k)\n",
    "print(\"Top k most common original_token:\")\n",
    "print(most_common)\n",
    "\n",
    "# Top k least common original_token\n",
    "least_common = df_results[\"original_token\"].value_counts().tail(k)\n",
    "print(\"\\nTop k least common original_token:\")\n",
    "print(least_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a9d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_path = f\"data/closest_tokens_distilbert_epsilon{epsilon}.csv\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # Append without header\n",
    "    df_results.to_csv(file_path, mode='a', header=False, index=False)\n",
    "else:\n",
    "    # Write with header\n",
    "    df_results.to_csv(file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "name_generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
