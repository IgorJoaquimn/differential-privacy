{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5b0851e9",
      "metadata": {
        "id": "5b0851e9"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1e89ba3",
      "metadata": {
        "id": "d1e89ba3"
      },
      "outputs": [],
      "source": [
        "# 1. Imports e setup\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from opacus import PrivacyEngine\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3a2b085",
      "metadata": {
        "id": "a3a2b085"
      },
      "outputs": [],
      "source": [
        "# If you desire reproducibility, run the following function:\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"\n",
        "    Sets the random seed for reproducibility across various runs.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import random\n",
        "    import numpy as np\n",
        "\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True # Makes training slower but ensures reproducibility\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3990344e",
      "metadata": {
        "id": "3990344e"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c05d2e",
      "metadata": {
        "id": "f6c05d2e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "def evaluate_model(model, dataloader):\n",
        "    \"\"\"\n",
        "    Avalia o modelo em um conjunto de dados e retorna as métricas de acurácia e F1-score\n",
        "    \"\"\"\n",
        "    # Certifique-se de que o modelo esteja em modo de avaliação\n",
        "    model.eval()\n",
        "\n",
        "    # Coletar todas as previsões e rótulos reais\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y, att_mask in tqdm(dataloader, desc=\"epoch\"):\n",
        "            x, y, att_mask = x.to(device), y.to(device), att_mask.to(device)\n",
        "            logits = model(x, attention_mask=att_mask)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            y_true.extend(y.cpu().tolist())\n",
        "            y_pred.extend(preds.cpu().tolist())\n",
        "\n",
        "    # Calcular métricas\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')  # usa média ponderada por classe\n",
        "\n",
        "    print(f\"Acurácia: {acc:.4f}\")\n",
        "    print(f\"F1-score (weighted): {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F5GkfjcVDYuz",
      "metadata": {
        "id": "F5GkfjcVDYuz"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "MAX_PHYSICAL_BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dd96e8a",
      "metadata": {
        "id": "4dd96e8a"
      },
      "outputs": [],
      "source": [
        "from dataset  import MovieDataset  # Certifique-se de que o arquivo dataset.py está no mesmo diretório\n",
        "\n",
        "train_dataset = MovieDataset(train=True)\n",
        "test_dataset = MovieDataset(train=False)\n",
        "\n",
        "num_labels = train_dataset.num_labels # Get num_labels from dataset\n",
        "\n",
        "# Instantiate DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d2551ce",
      "metadata": {
        "id": "0d2551ce"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3e125c8",
      "metadata": {
        "id": "d3e125c8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a18c4672",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a18c4672",
        "outputId": "25f75b36-e7ac-49e6-9a39-e863f75ac2aa"
      },
      "outputs": [],
      "source": [
        "from models.madlib import MadlibModel\n",
        "model = MadlibModel(2,epsilon=5).to(device).train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "121c6879",
      "metadata": {
        "id": "121c6879"
      },
      "outputs": [],
      "source": [
        "criterion = CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "num_epochs = 3\n",
        "total_steps = len(train_loader) * num_epochs\n",
        "warmup_steps = int(0.1 * total_steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8a3d847",
      "metadata": {
        "id": "b8a3d847"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y, att_mask in tqdm(dataloader, desc=\"epoch\"):\n",
        "            x, y, att_mask = x.to(device), y.to(device), att_mask.to(device)\n",
        "            logits = model(x, attention_mask=att_mask)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            y_true.extend(y.cpu().tolist())\n",
        "            y_pred.extend(preds.cpu().tolist())\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"Validation Accuracy: {acc:.4f}, F1-Score: {f1:.4f}\")\n",
        "    return acc, f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d90a4a64",
      "metadata": {
        "id": "d90a4a64"
      },
      "outputs": [],
      "source": [
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for step, (x, y, att_mask) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\")):\n",
        "        x, y, att_mask = x.to(device), y.to(device), att_mask.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x, attention_mask=att_mask)\n",
        "        loss = criterion(logits, y.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    evaluate(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8857d2c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Save the state_dict\n",
        "PATH = \"model_weights.pth\"\n",
        "torch.save(model.state_dict(), PATH)\n",
        "print(f\"Model weights saved to {PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6db814fa",
      "metadata": {
        "id": "6db814fa"
      },
      "source": [
        "# DP-SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sdL8xH7YDiYF",
      "metadata": {
        "id": "sdL8xH7YDiYF"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 3\n",
        "LOGGING_INTERVAL = 5000 # once every how many steps we run evaluation cycle and report metrics\n",
        "EPSILON = 7.5\n",
        "DELTA = 1 / len(train_loader) # Parameter for privacy accounting. Probability of not achieving privacy guarantees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06d28e45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06d28e45",
        "outputId": "b66256c9-9e9f-4dd7-a0ea-4dbd4803a014"
      },
      "outputs": [],
      "source": [
        "from opacus import PrivacyEngine\n",
        "\n",
        "MAX_GRAD_NORM = 0.1\n",
        "\n",
        "privacy_engine = PrivacyEngine()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, eps=1e-8)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "model, optimizer, train_dataloader = privacy_engine.make_private_with_epsilon(\n",
        "    module=model,\n",
        "    optimizer=optimizer,\n",
        "    data_loader=train_loader,\n",
        "    target_delta=DELTA,\n",
        "    target_epsilon=EPSILON,\n",
        "    epochs=EPOCHS,\n",
        "    max_grad_norm=MAX_GRAD_NORM,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YH0_I7bjEBqy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "YH0_I7bjEBqy",
        "outputId": "3d62d8ea-e0ea-4c6b-a4eb-93c719ac4e56"
      },
      "outputs": [],
      "source": [
        "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    with BatchMemoryManager(\n",
        "        data_loader=train_dataloader,\n",
        "        max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE,\n",
        "        optimizer=optimizer\n",
        "    ) as memory_safe_data_loader:\n",
        "        for step, (x, y, att_mask) in enumerate(tqdm(memory_safe_data_loader)):\n",
        "            x, y, att_mask = x.to(device), y.to(device), att_mask.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x, attention_mask=att_mask)\n",
        "            loss = criterion(logits, y.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f666b4e7",
      "metadata": {
        "id": "f666b4e7"
      },
      "outputs": [],
      "source": [
        "# 6. Cálculo do epsilon após o treino E avaliação do modelo\n",
        "epsilon = privacy_engine.accountant.get_epsilon(delta=1e-5)\n",
        "print(f\"ε = {epsilon:.2f}, δ = 1e-5\")\n",
        "evaluate_model(model, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83552006",
      "metadata": {
        "id": "83552006"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e34d57d",
      "metadata": {
        "id": "6e34d57d"
      },
      "outputs": [],
      "source": [
        "# --- BASELINE SEM PRIVACIDADE ---\n",
        "from torch.optim import Adam\n",
        "\n",
        "model_baseline = TextClassifier(BaselineModel(),embedding_dim, num_classes).to(device)\n",
        "optimizer = Adam(model_baseline.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_baseline.train()\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model_baseline(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"[BASELINE] Epoch {epoch+1} - Loss: {total_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd0c0b0",
      "metadata": {
        "id": "efd0c0b0"
      },
      "outputs": [],
      "source": [
        "evaluate_model(model_baseline, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e414ca",
      "metadata": {
        "id": "93e414ca"
      },
      "source": [
        "# Embedding Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "169ed394",
      "metadata": {
        "id": "169ed394"
      },
      "outputs": [],
      "source": [
        "def add_noise_to_embeddings(embedding_layer, sigma=0.1):\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn_like(embedding_layer.weight) * sigma\n",
        "        embedding_layer.weight.add_(noise)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a48140d",
      "metadata": {
        "id": "3a48140d"
      },
      "outputs": [],
      "source": [
        "# --- EMBEDDING PERTURBATION ---\n",
        "model_embed = TextClassifier(BaselineModel(),embedding_dim, num_classes).to(device)\n",
        "\n",
        "# Aplica ruído antes do treino\n",
        "add_noise_to_embeddings(model_embed.embedding, sigma=0.1)\n",
        "\n",
        "optimizer = Adam(model_embed.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_embed.train()\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model_embed(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"[EMBED NOISE] Epoch {epoch+1} - Loss: {total_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3055b7a1",
      "metadata": {
        "id": "3055b7a1"
      },
      "outputs": [],
      "source": [
        "evaluate_model(model_embed, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c64e254",
      "metadata": {
        "id": "0c64e254"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Parâmetros\n",
        "sigma = 0.1          # mesmo que você usou ao aplicar ruído\n",
        "delta = 1e-5\n",
        "sensitivity = 1.0    # padrão\n",
        "\n",
        "# Fórmula para mecanismo Gaussiano (epsilon aproximado)\n",
        "epsilon = (np.sqrt(2 * np.log(1.25 / delta)) * sensitivity) / sigma\n",
        "\n",
        "# Se aplicou ruído T vezes (ex: por época), multiplique:\n",
        "T = 3  # ou 3, se adicionou ruído por época\n",
        "epsilon_total = epsilon * T\n",
        "\n",
        "print(f\"ε ≈ {epsilon_total:.4f} (para σ = {sigma}, δ = {delta}, T = {T})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed74fe9f",
      "metadata": {
        "id": "ed74fe9f"
      },
      "source": [
        "# TEM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ca5780",
      "metadata": {
        "id": "d7ca5780"
      },
      "outputs": [],
      "source": [
        "from models.tem import TEMModel\n",
        "model_tem = TextClassifier(TEMModel(),embedding_dim, num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d056dda",
      "metadata": {
        "id": "8d056dda"
      },
      "outputs": [],
      "source": [
        "def apply_tem_noise(embedding_layer: torch.nn.Embedding, sigma: float = 0.1):\n",
        "    \"\"\"\n",
        "    Aplica ruído gaussiano diretamente na camada de embeddings.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn_like(embedding_layer.weight) * sigma\n",
        "        embedding_layer.weight.add_(noise)\n",
        "\n",
        "# --- Aplicar TEM antes do treino ---\n",
        "sigma_tem = 1.0  # ajuste para obter melhor privacidade (ε ↓)\n",
        "apply_tem_noise(model_tem.embedding, sigma=sigma_tem)\n",
        "print(f\"TEM aplicado com sigma = {sigma_tem}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbf9c63d",
      "metadata": {
        "id": "bbf9c63d"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model_tem.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_tem.train()\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model_tem(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"[TEM] Epoch {epoch+1} - Loss: {total_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c56d611",
      "metadata": {
        "id": "5c56d611"
      },
      "outputs": [],
      "source": [
        "evaluate_model(model_tem, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ea323fe",
      "metadata": {
        "id": "6ea323fe"
      },
      "source": [
        "# MADLIB - TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa269b8a",
      "metadata": {
        "id": "aa269b8a"
      },
      "outputs": [],
      "source": [
        "from models.madlib import MadlibModel\n",
        "\n",
        "model = TextClassifier(MadlibModel(epsilon=5),embedding_dim, num_classes).to(device)\n",
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f44cb7d",
      "metadata": {
        "id": "5f44cb7d"
      },
      "source": [
        "# DP-SGD + TEM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46bdfed6",
      "metadata": {
        "id": "46bdfed6"
      },
      "outputs": [],
      "source": [
        "# Instancia o modelo\n",
        "model_combo = TextClassifier(TEMModel(),embedding_dim, num_classes).to(device)\n",
        "\n",
        "# --- Aplica ruído TEM às embeddings ---\n",
        "sigma_tem = 1.0\n",
        "def apply_tem_noise(embedding_layer: torch.nn.Embedding, sigma: float = 0.1):\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn_like(embedding_layer.weight) * sigma\n",
        "        embedding_layer.weight.add_(noise)\n",
        "\n",
        "apply_tem_noise(model_combo.embedding, sigma=sigma_tem)\n",
        "print(f\"[COMBO] TEM aplicado com σ = {sigma_tem}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ea9981",
      "metadata": {
        "id": "d5ea9981"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model_combo.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Configura o PrivacyEngine\n",
        "privacy_engine = PrivacyEngine()\n",
        "model_combo, optimizer, dataloader_combo = privacy_engine.make_private(\n",
        "    module=model_combo,\n",
        "    optimizer=optimizer,\n",
        "    data_loader=dataloader,\n",
        "    noise_multiplier=1.0,      # σ do DP-SGD\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "\n",
        "# Treinamento\n",
        "model_combo.train()\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    for x, y in dataloader_combo:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model_combo(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"[COMBO] Epoch {epoch+1} - Loss: {total_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24822327",
      "metadata": {
        "id": "24822327"
      },
      "outputs": [],
      "source": [
        "epsilon_combo = privacy_engine.accountant.get_epsilon(delta=1e-5)\n",
        "print(f\"[COMBO] ε (DP-SGD): {epsilon_combo:.2f} | δ = 1e-5\")\n",
        "print(f\"[COMBO] TEM aplicado com σ = {sigma_tem} (ε estimado separadamente ≈ {4.84 if sigma_tem==1.0 else 'recalcular'})\")\n",
        "evaluate_model(model_combo, dataloader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
